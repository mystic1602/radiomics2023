{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43d196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso,LassoCV,LassoLarsCV,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,KFold,RepeatedKFold,GridSearchCV\n",
    "from scipy.stats import pearsonr, ttest_ind, levene\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from scipy.stats import pearsonr, ttest_ind, levene\n",
    "import itertools\n",
    "import time\n",
    "from array import array\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from openpyxl import Workbook\n",
    "import xlwings as xw\n",
    "from openpyxl.styles import Font\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b6654",
   "metadata": {},
   "source": [
    "# read total file and save to train set and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1930e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read file\n",
    "df = pd.read_excel(feature all.xlsx)\n",
    "#Extract label=0 from the training set\n",
    "df = df.loc[(df['group'] == 'train') & (df['label'] == 0)]  \n",
    "df = df.drop(['group', 'label'], axis=1)\n",
    "df.to_excel(train_0.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# read file\n",
    "df = pd.read_excel(feature all.xlsx)\n",
    "#Extract label=1 from the training set\n",
    "df = df.loc[(df['group'] == 'train') & (df['label'] == 1)] \n",
    "df = df.drop(['group', 'label'], axis=1)\n",
    "\n",
    "df.to_excel(train_1.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read file\n",
    "df = pd.read_excel(feature all.xlsx)\n",
    "#Extract label=0 from the test set\n",
    "df = df.loc[(df['group'] == 'test') & (df['label'] == 0)]  \n",
    "df = df.drop(['group', 'label'], axis=1)\n",
    "df.to_excel(test_0.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# read file\n",
    "df = pd.read_excel(feature all.xlsx)\n",
    "#Extract label=1 from the test set\n",
    "df = df.loc[(df['group'] == 'test') & (df['label'] == 1)] #Delete TMV, preserve PTV\n",
    "df = df.drop(['group', 'label'], axis=1)\n",
    "\n",
    "df.to_excel(test_1.xlsx', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fcc5ac",
   "metadata": {},
   "source": [
    "# create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx1_filePath = 'train_0.xlsx'\n",
    "xlsx2_filePath = 'train_1.xlsx'\n",
    "data_1 = pd.read_excel(xlsx1_filePath)\n",
    "data_2 = pd.read_excel(xlsx2_filePath)\n",
    "rows_1,__ = data_1.shape\n",
    "rows_2,__ = data_2.shape\n",
    "data_1.insert(0,'label',[0]*rows_1)\n",
    "data_2.insert(0,'label',[1]*rows_2)\n",
    "data = pd.concat([data_1,data_2])\n",
    "data = shuffle(data)\n",
    "data = data.fillna(0)\n",
    "X= data[data.columns[1:]]\n",
    "y= data['label']\n",
    "colNames = X.columns\n",
    "X= X.astype(np.float64)\n",
    "X= StandardScaler().fit_transform(X)\n",
    "X= pd.DataFrame(X)\n",
    "X.columns = colNames\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7621e",
   "metadata": {},
   "source": [
    "# t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4570eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test for feature selection\n",
    "index = []\n",
    "for colName in data.columns[1:]:\n",
    "    if levene(data_1[colName],data_2[colName])[1] > 0.05:\n",
    "        if ttest_ind(data_1[colName],data_2[colName])[1] < 0.05:\n",
    "            index.append(colName)\n",
    "    else:\n",
    "        if ttest_ind(data_1[colName],data_2[colName],equal_var = False)[1] < 0.05:\n",
    "            index.append(colName)\n",
    "print(len(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e1831",
   "metadata": {},
   "source": [
    "# standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to select the 'positive' features\n",
    "if 'label' not in index:index = ['label']+index\n",
    "data_1 = data_1[index]\n",
    "data_2 = data_2[index]\n",
    "data = pd.concat([data_1,data_2])\n",
    "data = shuffle(data)\n",
    "data.index = range(len(data))#re-label after mixure\n",
    "X = data[data.columns[1:]]\n",
    "y = data['label']\n",
    "X = X.apply(pd.to_numeric,errors = 'ignore') # transform the type of the data \n",
    "colNames = X.columns # to read the feature's name\n",
    "X = X.fillna(0)\n",
    "X = X.astype(np.float64)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns = colNames\n",
    "X_raw = X \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f447a",
   "metadata": {},
   "source": [
    "# lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f441c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lasso for further feature selection\n",
    "alphas = np.logspace(-3,0,50)\n",
    "model_lassoCV = LassoCV(alphas = alphas, cv =5, max_iter = 100000).fit(X,y)\n",
    "\n",
    "print(model_lassoCV.alpha_)\n",
    "coef = pd.Series(model_lassoCV.coef_,index = X.columns)\n",
    "print('Lasso picked ' + str(sum(coef !=0))+' variables and eliminated the other ' + str(sum(coef == 0)))\n",
    "\n",
    "index = coef[coef != 0].index\n",
    "\n",
    "\n",
    "X = X[index]\n",
    "X.head()\n",
    "print(coef[coef !=0])\n",
    "\n",
    "\n",
    "#Delete the rest of the data in the train set and keep only the filtered features\n",
    "df1 = pd.read_excel(train_0.xlsx)\n",
    "df2 = pd.read_excel(train_1.xlsx)\n",
    "\n",
    "df1 = df1.filter(index)\n",
    "df2 = df2.filter(index)\n",
    "\n",
    "df1.to_excel(train_0.xlsx, index=False)\n",
    "df2.to_excel(train_1.xlsx, index=False)\n",
    "\n",
    "\n",
    "#Delete the rest of the data in the test set and keep only the filtered features\n",
    "df1 = pd.read_excel(test_0.xlsx)\n",
    "df2 = pd.read_excel(test_1.xlsx)\n",
    "\n",
    "df1 = df1.filter(index)\n",
    "df2 = df2.filter(index)\n",
    "\n",
    "df1.to_excel(test_0.xlsx, index=False)\n",
    "df2.to_excel(test_1.xlsx, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a3745",
   "metadata": {},
   "source": [
    "# plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca8570",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(5, 5), dpi= 80)  \n",
    "plt.title(\"Radiomic Dendograms\", fontsize=22)  \n",
    "dend = shc.dendrogram(shc.linkage(X[:].T, method='ward'), labels=X.columns, color_threshold=10)  #参数调整\n",
    "plt.xticks(fontsize=12,rotation = 60, ha = 'right')\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "MSEs = model_lassoCV.mse_path_\n",
    "'''\n",
    "MSEs_mean, MSE_std = [],[]\n",
    "for i in range(len(MESs)):\n",
    "    MSEs_mean.append(MSEs[i].mean())\n",
    "    MSEs_std.append(MSEs[i].std())\n",
    "'''\n",
    "\n",
    "MSEs_mean = np.apply_along_axis(np.mean,1,MSEs)\n",
    "MSEs_std = np.apply_along_axis(np.std,1,MSEs)\n",
    "\n",
    "plt.figure() # dpi = 300\n",
    "plt.rcParams['savefig.dpi'] = 1200 \n",
    "plt.rcParams['figure.dpi'] = 1200 \n",
    "plt.errorbar(model_lassoCV.alphas_,MSEs_mean\n",
    "            ,yerr = MSEs_std\n",
    "            ,fmt = 'o' \n",
    "            ,ms = 3 # dot size\n",
    "            ,mfc = 'r' # dot color\n",
    "            ,mec = 'r' # dot margin color\n",
    "            ,ecolor = 'lightblue' \n",
    "            ,elinewidth = 2 # error bar width\n",
    "            ,capsize = 4  # cap length of error bar \n",
    "            ,capthick = 1) \n",
    "plt.semilogx()\n",
    "plt.axvline(model_lassoCV.alpha_,color = 'black',ls = '--')\n",
    "plt.xlabel('Lamda')\n",
    "plt.ylabel('MSE')\n",
    "ax = plt.gca()\n",
    "y_major_locator = ticker.MultipleLocator(0.1)\n",
    "ax.yaxis.set_major_locator(y_major_locator)\n",
    "plt.savefig(\"lasso1.jpg\")\n",
    "plt.show()\n",
    "\n",
    "coefs = model_lassoCV.path(X_raw,y,alphas = alphas, max_iter = 10000000)[1].T\n",
    "plt.figure()\n",
    "plt.semilogx(model_lassoCV.alphas_,coefs,'-')\n",
    "plt.axvline(model_lassoCV.alpha_,color = 'black',ls = '--')\n",
    "plt.xlabel('Lamda')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.savefig(\"lasso2.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f2acf",
   "metadata": {},
   "source": [
    "# define train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train，y_train\n",
    "xlsx1_filePath = 'train_0.xlsx'\n",
    "xlsx2_filePath = 'train_1.xlsx'\n",
    "data_1 = pd.read_excel(xlsx1_filePath)\n",
    "data_2 = pd.read_excel(xlsx2_filePath)\n",
    "rows_1,__ = data_1.shape\n",
    "rows_2,__ = data_2.shape\n",
    "data_1.insert(0,'label',[0]*rows_1)\n",
    "data_2.insert(0,'label',[1]*rows_2)\n",
    "data = pd.concat([data_1,data_2])\n",
    "data = shuffle(data)\n",
    "data = data.fillna(0)\n",
    "X_train= data[data.columns[1:]]\n",
    "y_train= data['label']\n",
    "colNames = X_train.columns\n",
    "X_train= X_train.astype(np.float64)\n",
    "X_train= StandardScaler().fit_transform(X_train)\n",
    "X_train= pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test，y_test\n",
    "xlsx1_filePath = 'test_0.xlsx'\n",
    "xlsx2_filePath = 'test_1.xlsx'\n",
    "data_1 = pd.read_excel(xlsx1_filePath)\n",
    "data_2 = pd.read_excel(xlsx2_filePath)\n",
    "rows_1,__ = data_1.shape\n",
    "rows_2,__ = data_2.shape\n",
    "data_1.insert(0,'label',[0]*rows_1)\n",
    "data_2.insert(0,'label',[1]*rows_2)\n",
    "data = pd.concat([data_1,data_2])\n",
    "data = shuffle(data)\n",
    "data = data.fillna(0)\n",
    "X_test = data[data.columns[1:]]\n",
    "y_test= data['label']\n",
    "colNames = X_test.columns\n",
    "X_test= X_test.astype(np.float64)\n",
    "X_test= StandardScaler().fit_transform(X_test)\n",
    "X_test= pd.DataFrame(X_test)\n",
    "\n",
    "X_test.to_csv('X_test.csv', index=None)\n",
    "y_test.to_csv('y_test.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0cbb6",
   "metadata": {},
   "source": [
    "# LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f036ce4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_LR = LogisticRegression(C=0.1)\n",
    "model_LR.fit(X_train, y_train)\n",
    "\n",
    "y_prob_train = model_LR.predict_proba(X_train)[:, 1]\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_prob_train)\n",
    "\n",
    "y_prob_test = model_LR.predict_proba(X_test)[:, 1]\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_prob_test)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Test set AUC: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "\n",
    "model_LR_best = LogisticRegression(C=grid.best_params_['C'])\n",
    "model_LR_best.fit(X_train, y_train)\n",
    "\n",
    "y_prob_train_best = model_LR_best.predict_proba(X_train)[:, 1]\n",
    "fpr_train_best, tpr_train_best, thresholds_train_best = roc_curve(y_train, y_prob_train_best)\n",
    "\n",
    "y_prob_test_best = model_LR_best.predict_proba(X_test)[:, 1]\n",
    "fpr_test_best, tpr_test_best, thresholds_test_best = roc_curve(y_test, y_prob_test_best)\n",
    "\n",
    "plt.plot(fpr_train_best, tpr_train_best)\n",
    "plt.plot(fpr_test_best, tpr_test_best)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.text(0.5, 0.3, f'Train AUC: {roc_auc_score(y_train, y_prob_train_best):.2f}\\nTest AUC: {roc_auc_score(y_test, y_prob_test_best):.2f}', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "print('coefficient：', model_LR.coef_)\n",
    "print('coefficient：', model_LR.将_)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_test = model_LR.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "TN = cm[1][1]\n",
    "FN = cm[1][0]\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "NPV = TN / (TN + FN)\n",
    "PPV = TP / (TP + FP)\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"NPV:\", NPV)\n",
    "print(\"PPV:\", PPV)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(y_prob_test.reshape(-1, 1))\n",
    "\n",
    "     \n",
    "                    \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert y_train to dataframe format\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "# Save y_train_df to specified path\n",
    "y_test_df.to_excel('y_train.xlsx')\n",
    "\n",
    "# Get the intercept and coefficients of the logistic regression model\n",
    "intercept = model_LR.intercept_\n",
    "coef = model_LR.coef_\n",
    "\n",
    "# Convert the coefficients to a one-dimensional array\n",
    "coef = coef.ravel()\n",
    "\n",
    "# Get the names of the features\n",
    "features = X.columns\n",
    "\n",
    "# Build the logistic regression formula string\n",
    "formula = \"y = 1 / (1 + exp(-(\" + str(intercept)\n",
    "for i in range(len(features)):\n",
    "    formula += \" + \" + str(coef[i]) + \" * \" + features[i]\n",
    "formula += \")))\"\n",
    "\n",
    "# Print the logistic regression formula\n",
    "print(formula)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
